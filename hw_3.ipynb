{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Op3ylwurVuZY"
   },
   "source": [
    "# **Введение в анализ данных**\n",
    "# **НИУ ВШЭ, 2019-2020 учебный год**\n",
    "**Домашнее задание №3**\n",
    "\n",
    "Задание выполнил: Соснин Артём"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J_McsmWRykZh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17396,
     "status": "ok",
     "timestamp": 1592394533206,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "2rNuN-ntzgtU",
    "outputId": "386eee29-00c6-45d2-c93e-965d28bd547c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-17 11:48:48--  https://www.dropbox.com/s/tg55q9mrziroyrs/train_subset.csv\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/tg55q9mrziroyrs/train_subset.csv [following]\n",
      "--2020-06-17 11:48:48--  https://www.dropbox.com/s/raw/tg55q9mrziroyrs/train_subset.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc2d29d6e092d5be72b33f569911.dl.dropboxusercontent.com/cd/0/inline/A51kF69ImZCRaryqEQl6-RwpDWEtZJr6E_QmXDm7xRK14LmSlXKIr9zPJgeDnm0bc3LKXMgVqKE98tJ9E_oJWrWLL69krXPLl3_ozg0aJM5bhueuImKm7XxoogTdQyzvzKM/file# [following]\n",
      "--2020-06-17 11:48:48--  https://uc2d29d6e092d5be72b33f569911.dl.dropboxusercontent.com/cd/0/inline/A51kF69ImZCRaryqEQl6-RwpDWEtZJr6E_QmXDm7xRK14LmSlXKIr9zPJgeDnm0bc3LKXMgVqKE98tJ9E_oJWrWLL69krXPLl3_ozg0aJM5bhueuImKm7XxoogTdQyzvzKM/file\n",
      "Resolving uc2d29d6e092d5be72b33f569911.dl.dropboxusercontent.com (uc2d29d6e092d5be72b33f569911.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6021:15::a27d:410f\n",
      "Connecting to uc2d29d6e092d5be72b33f569911.dl.dropboxusercontent.com (uc2d29d6e092d5be72b33f569911.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19213119 (18M) [text/plain]\n",
      "Saving to: ‘train_subset.csv.1’\n",
      "\n",
      "train_subset.csv.1  100%[===================>]  18.32M  18.7MB/s    in 1.0s    \n",
      "\n",
      "2020-06-17 11:48:50 (18.7 MB/s) - ‘train_subset.csv.1’ saved [19213119/19213119]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Датасет можно скачать здесь\n",
    "\n",
    "!wget https://www.dropbox.com/s/tg55q9mrziroyrs/train_subset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_NH3y4xGz7Sd"
   },
   "source": [
    "**Данные**  \n",
    "Мы имеем дело с данными с торговой платформы Avito. Для каждого товара представлены следующие параметры:  \n",
    "\n",
    "*   title\n",
    "*   description\n",
    "*   Category_name\n",
    "*   Category  \n",
    "Имеется информация об объектах 50 классов. Задача: по новым объектам (title, description) предсказать Category. (Очевидно, что параметр Category_name для предсказания классов использовать нельзя)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17366,
     "status": "ok",
     "timestamp": 1592394533208,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "EvYdJV9B0Wu8",
    "outputId": "8ae56e98-240f-4298-9b3e-5bbb1d9ad8a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>Category_name</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382220</th>\n",
       "      <td>Прихожая</td>\n",
       "      <td>В хорошем состоянии. Торг</td>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397529</th>\n",
       "      <td>Кордиант 215/55/16 Летние</td>\n",
       "      <td>Кордиант 215/55/16 Летние/\\n /\\nАртикул: 1737l...</td>\n",
       "      <td>Запчасти и аксессуары</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584569</th>\n",
       "      <td>Стол</td>\n",
       "      <td>Стол, 2 рабочих места . Стол серого цвета, в д...</td>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513100</th>\n",
       "      <td>Комбинезон</td>\n",
       "      <td>Размер-42/44</td>\n",
       "      <td>Одежда, обувь, аксессуары</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091886</th>\n",
       "      <td>Ветровка</td>\n",
       "      <td>На 2 года</td>\n",
       "      <td>Детская одежда и обувь</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  ... Category\n",
       "id                                  ...         \n",
       "382220                    Прихожая  ...       20\n",
       "397529   Кордиант 215/55/16 Летние  ...       10\n",
       "584569                        Стол  ...       20\n",
       "2513100                 Комбинезон  ...       27\n",
       "1091886                   Ветровка  ...       29\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train_subset.csv\", index_col='id')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17339,
     "status": "ok",
     "timestamp": 1592394533209,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "XJds8qAl0cA4",
    "outputId": "ddab270e-2431-4dbf-aca6-073be5008a9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 4)"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VLjrLHrW0jvg"
   },
   "outputs": [],
   "source": [
    "X = data[['title', 'description']].to_numpy()\n",
    "y = data['Category'].to_numpy()\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PiMEUgDS0rqE"
   },
   "source": [
    "Сразу разделим выборку на train и test. Никакие данные из test для обучения использовать нельзя!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zx_qV3Y10t5J"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18165,
     "status": "ok",
     "timestamp": 1592394534110,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "d5Z9ixw20zjx",
    "outputId": "7347a50a-56df-47c7-a266-66d565e416e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Сапоги 46 размер новые', 'Сапоги 46 размер новые'],\n",
       "       ['Светильники потолочный swarovski',\n",
       "        'светильники потолочные swarovski 6 штук , цена за штуку. В эксплуатации 2 года , продаются в связи со сменой интерьера в квартире'],\n",
       "       ['iPhone 7 plus 128GB Red красный в наличии',\n",
       "        '\\xa0/\\n/\\n Данная цена только для подписчиков Instagram: iQmac/\\n/\\n Новый красный айфон 7 Plus в наличии это элегантный и мощный смартфон, который готов в полной мере раскрыть новые возможности iOS 10. Аппарат с 4-ядерным процессором А10 и 3 ГБ ОЗУ с легкостью решает самые ресурсоемкие задачи, позволяя наслаждаться быстродействием «тяжелых» приложений и игр на 5,5-дюймовом дисплее. Аппарат получил экран, как у iPad Pro, так что картинка теперь соответствует кинематографическому стандарту.'],\n",
       "       ['Пион Ирис Ромашка рассада',\n",
       "        'Пион куст 500 р ( более 10 шт)/\\nСаженец/ корень 100р/\\nРастут у нас более 70 лет/\\nРозовые, бордовые и белые/\\nНа фото цветы 2018г/\\nП. Зубчаниновка/\\nлибо пл. Революции/\\nЕсть ирисы, ромашка, клубника, боярышник и ирга'],\n",
       "       ['Кофта', 'Состояние отличное']], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZtFKHlQr0_iZ"
   },
   "source": [
    "**Токенизация (1 балл)**  \n",
    "Токенизация -- разбиение текста на мелкие части, которые можно обработать машинными методами. Можно использовать разные алгоритмы токенизации. Давайте пока остановимся на простом WordPunctTokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18142,
     "status": "ok",
     "timestamp": 1592394534112,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "rbm4vYrI1DxO",
    "outputId": "c644cb53-43cb-4992-e314-d6e360d8291c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: Здраствуйте. Я3, Кирилл. Хотел бы чтобы вы сделали игру, 3Д-экшон суть такова...\n",
      "after: здраствуйте . я3 , кирилл . хотел бы чтобы вы сделали игру , 3д - экшон суть такова ...\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "\n",
    "def preprocess(text: str) -> str:\n",
    "    return ' '.join(tokenizer.tokenize(text.lower()))\n",
    "\n",
    "\n",
    "text = 'Здраствуйте. Я3, Кирилл. Хотел бы чтобы вы сделали игру, 3Д-экшон суть такова...'\n",
    "print(\"before:\", text,)\n",
    "print(\"after:\", preprocess(text),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MuWF6Jv817TB"
   },
   "source": [
    "Задание: Токенизируйте title и description в train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q0NJ1PU73jrx"
   },
   "outputs": [],
   "source": [
    "X_train=np.asarray([np.asarray([preprocess(s) for s in X_train[i]]) for i in range(X_train.shape[0])])\n",
    "X_test=np.asarray([np.asarray([preprocess(s) for s in X_test[i]]) for i in range(X_test.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19145,
     "status": "ok",
     "timestamp": 1592394535166,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "0-8WUbHi1_jH",
    "outputId": "25895fc0-6dff-4efc-fba9-06bc7ae5688a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['сапоги 46 размер новые', 'сапоги 46 размер новые'],\n",
       "       ['светильники потолочный swarovski',\n",
       "        'светильники потолочные swarovski 6 штук , цена за штуку . в эксплуатации 2 года , продаются в связи со сменой интерьера в квартире'],\n",
       "       ['iphone 7 plus 128gb red красный в наличии',\n",
       "        '/ / данная цена только для подписчиков instagram : iqmac / / новый красный айфон 7 plus в наличии это элегантный и мощный смартфон , который готов в полной мере раскрыть новые возможности ios 10 . аппарат с 4 - ядерным процессором а10 и 3 гб озу с легкостью решает самые ресурсоемкие задачи , позволяя наслаждаться быстродействием « тяжелых » приложений и игр на 5 , 5 - дюймовом дисплее . аппарат получил экран , как у ipad pro , так что картинка теперь соответствует кинематографическому стандарту .'],\n",
       "       ['пион ирис ромашка рассада',\n",
       "        'пион куст 500 р ( более 10 шт )/ саженец / корень 100р / растут у нас более 70 лет / розовые , бордовые и белые / на фото цветы 2018г / п . зубчаниновка / либо пл . революции / есть ирисы , ромашка , клубника , боярышник и ирга'],\n",
       "       ['кофта', 'состояние отличное'],\n",
       "       ['1 - к квартира , 33 м² , 4 / 5 эт .',\n",
       "        'продаётся уютная , тёплая квартира в экологически - чистом районе города , рядом сосновый бор , всегда чистый воздух . дом 2004 г ., хорошие соседи , на площадке 2 - е квартиры , развитая инфраструктура , в шаговой доступности поликлиника , школа , тк « орбита », вещевой рынок . квартира в хорошем состоянии . подходит под ипотеку , долгов , обременений , перепланировке нет . в квартире натяжные потолки , в ванной комнате стены выполнены из влагостойких стеновых панелей . возможен обмен на квартиру в г . магнитогорске , торг .'],\n",
       "       ['платье новое 60 размера',\n",
       "        'платье 60 размера , новое , красивого темно синего цвета , из трикотажной ткани : вискоза 95 %, эластина 5 % . а - образного силуэта с рукавом 2 / 3 . длинна по спинке 113см .'],\n",
       "       ['ваз 2114 samara , 2007',\n",
       "        'продам ваз 2114 2007 г . в . в хорошем состоянии . / 2 владельца , птс оригинал . / машина в родной краске , в дтп никогда не была ,/ днище целое не ржавое . по ходовой нареканий нет , сел и поехал . / имеется музыка , сигнализация 2 комплекта ключей , птф , передние стеклоподъемники ./ небольшой торг при осмотре . / обмен не интересует .'],\n",
       "       ['наушники блутус',\n",
       "        'долго держат заряд 4 - 5 часов , можно и больше при средней громкости выжать из них . вкладыши .'],\n",
       "       ['пальто tommy hilfiger',\n",
       "        'состояние нового . промахнулась с размером . пальто до - 10 - 12 градусов . / возможна пересылка по почте']],\n",
       "      dtype='<U3491')"
      ]
     },
     "execution_count": 95,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8cJ4H4xT2qOq"
   },
   "outputs": [],
   "source": [
    "assert X_train[10][1] == 'продам иж планета 3 , 76 год , ( стоит на старом учёте , документы утеряны ) на ходу , хорошее состояние , все интересующие вопросы по телефону ( с родной коляской на 3 тысячи дороже ) . торга не будет .'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LZZpViMB-L2_"
   },
   "source": [
    "**BOW (1.5 балла)**  \n",
    "Один из традиционных подходов -- построение bag of words.\n",
    "\n",
    "Метод состоит в следующем:\n",
    "\n",
    "Составить словарь самых часто встречающихся слов в train data  \n",
    "Для каждого примера из train посчитать, сколько раз каждое слово из словаря в нём встречается  \n",
    "В sklearn есть CountVectorizer, но в этом задании его использовать нельзя.\n",
    "\n",
    "Задание: Найдите k самых частых слов, отсортируйте их по убыванию частотности (k=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iWu56smYKiRD"
   },
   "source": [
    "Сначала создадим массив всех слов allwords, которые встречаются в X_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A30fCL3tg-OA"
   },
   "outputs": [],
   "source": [
    "allwords=np.concatenate(np.concatenate(np.asarray([[ sr.split() for sr in X_train[i]] for i in range(X_train.shape[0])])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lh2x-zUmKyhb"
   },
   "source": [
    "Теперь с помощью Counter, создадим словарь bow_vocabulary, где для каждого слова из allwords указано колочество раз, которое оно встречается в allwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pl_c97HURNu0"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "bow_vocabulary=Counter(allwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fxi85xxCLS_r"
   },
   "source": [
    "Отсортируем bow_vocabulary по частоте встречаемости слов. bow - это отсортированный список 10000 самых популярных слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sG3y4e9UROdS"
   },
   "outputs": [],
   "source": [
    "bow=sorted(bow_vocabulary, key=bow_vocabulary.get,reverse=True)[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dIbEEck5NWlb"
   },
   "outputs": [],
   "source": [
    "# только здесь то, что подразумевалось под  bow_vocabulary у меня называется bow\n",
    "assert sorted(bow)[::200] == ['!', '12500', '270', '700', 'by', 'gh', 'michael', 'sonata', 'ø', 'аудиоподготовка', 'большим', 'веса', 'воспроизведения','габариты',\n",
    "'гтд', 'джинсами', 'доступность', 'загрузки', 'зимней', 'использовался', 'квартала', 'коммуникации', 'кошки', 'лакированные', 'магазин', 'металл', 'мск', \n",
    "'натуральным', 'носке', 'одному', 'отвечаем', 'пассат', 'плотно', 'покраску','постоянные', 'примеры', 'просьба', 'размещайте', 'репетитор', 'сантехник', \n",
    "'сидения', 'современного', 'стала', 'схема', 'тон', 'удлиненная', 'фасад', 'цветами', 'шея', 'эту']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YNSzig1r3CsB"
   },
   "outputs": [],
   "source": [
    "def text_to_bow(text: str) -> np.array:\n",
    "    \"\"\"\n",
    "    Возвращает вектор, где для каждого слова из most_common\n",
    "    указано количество его употреблений\n",
    "    \"\"\" \n",
    "    words=text.split()\n",
    "    return np.asarray([words.count(word) for word in bow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7eu3T0tK40QU"
   },
   "outputs": [],
   "source": [
    "assert np.allclose(np.where(text_to_bow(\"сдаётся уютный , тёплый гараж для стартапов в ml\") != 0)[0],\n",
    "                   np.array([   1,    4,   12,  565,  866, 1601, 2539, 4063])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ht5cj3qQ7qlI"
   },
   "outputs": [],
   "source": [
    "def items_to_bow(items: np.array) -> np.array:\n",
    "    \"\"\" Для каждого товара возвращает вектор его bow \"\"\"\n",
    "    # Давайте для начала попробуем строить bow только из description товара\n",
    "    # assert ниже написан для bow из description\n",
    "    \n",
    "    return np.asarray([text_to_bow(item[1]) for item in items])\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XmtmIRWa8Jnd"
   },
   "outputs": [],
   "source": [
    "assert np.allclose(np.where(items_to_bow([X_train[42]])[0] != 0),\n",
    "                   np.array([   0, 1, 2, 5, 6, 7, 12, 27, 41, 49, 110,\n",
    "                                189,  208,  221, 2032, 3052, 7179, 9568]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bp5qAOySnb7v"
   },
   "outputs": [],
   "source": [
    "X_train_bow = items_to_bow(X_train)\n",
    "X_test_bow = items_to_bow(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sf34Jrqlsg5q"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YvawZbVztKZq"
   },
   "source": [
    "**Логистическая регрессия и SVC (1 балл)**  \n",
    "Теперь описание каждого товара представлено, как точка в многомерном пространстве. Очень важно запомнить эту идею: дальше мы будем рассматривать разные способы перехода от текста к точке в пространстве.\n",
    "\n",
    "Для BOW каждое измерение в пространстве -- какое-то слово. Мы предполагаем, что текст описывается набором каких-то популярных слов, которые в нём встречаются, а близкие по смыслу тексты будут использовать одинаковые слова.\n",
    "\n",
    "Обучите логистическую регрессию и SVC с базовыми параметрами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DafwE3FYMEPJ"
   },
   "source": [
    "Так как матрицы X_train, X_test содержать много нулей, дальше я буду работать с разреженными матрицами, чтобы уменьшить объем используемой памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qXW37a6K6x3K"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "X_test_bow_csr = csr_matrix(X_test_bow)\n",
    "X_train_bow_csr = csr_matrix(X_train_bow)\n",
    "\n",
    "del X_test_bow\n",
    "del X_train_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 431517,
     "status": "ok",
     "timestamp": 1592394947819,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "3pQNp53htPYU",
    "outputId": "a877d93d-eff9-4fbb-b045-4a1b75fefce3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7011111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "bow_model = LogisticRegression(max_iter=100).fit(X_train_bow_csr, y_train)\n",
    "print(accuracy_score(bow_model.predict(X_test_bow_csr), y_test))\n",
    "\n",
    "assert accuracy_score(bow_model.predict(X_test_bow_csr), y_test) > 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 435690,
     "status": "ok",
     "timestamp": 1592394952024,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "_RoLZvHs9sal",
    "outputId": "b624fc7e-234a-48fd-f8f7-9bb39bad3d57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6828888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "bow_model = LinearSVC(max_iter=70).fit(X_train_bow_csr, y_train)\n",
    "print(accuracy_score(bow_model.predict(X_test_bow_csr), y_test))\n",
    "\n",
    "assert accuracy_score(bow_model.predict(X_test_bow_csr), y_test) > 0.68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P7L-XXVCqCIy"
   },
   "source": [
    "**Модификация признаков (0.5 балла)**  \n",
    "Добавьте title товара в bow с произвольным весом, как изменится качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7m8rPjIiqFEE"
   },
   "outputs": [],
   "source": [
    "def items_to_bow_title(items: np.array) -> np.array:\n",
    "    \"\"\" аналогичная функция items_to_bow, только теперь возвращает вектор для title товара\"\"\"\n",
    "    \n",
    "    return np.asarray([text_to_bow(item[0]) for item in items])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GrUJnO52Pb6w"
   },
   "source": [
    "Сложим для каждого товара вектора его title и description, вектор title возьмем с весом 2, так получается лучшее качество. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3755,
     "status": "ok",
     "timestamp": 1592395285171,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "pfCuVRSFsn6X"
   },
   "outputs": [],
   "source": [
    "X_train_bow_cdt=csr_matrix(X_train_bow_csr+2*items_to_bow_title(X_train))\n",
    "X_test_bow_cdt=csr_matrix(X_test_bow_csr+2*items_to_bow_title(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1592395285173,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "5mwZ7ns_wuqk",
    "outputId": "a3d6ba6b-2485-42b8-ca5c-94dc3ff3a5f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество логистической регресии:  0.7943333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=100).fit(X_train_bow_cdt, y_train)\n",
    "print('Качество логистической регресии: ',accuracy_score(model.predict(X_test_bow_cdt), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1592395285175,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "v0CTCHJ1tpC5",
    "outputId": "bd446d06-6863-4f9d-815c-7eb20b6c8cad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество SVC:  0.7625555555555555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(max_iter=70).fit(X_train_bow_cdt, y_train)\n",
    "print('Качество SVC: ',accuracy_score(model.predict(X_test_bow_cdt), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FUJwaLPlUaP8"
   },
   "source": [
    "Как видно, качество улучшилось примерно на 0,09 для логистической регрессии и на 0,08 для SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4dWCxVRXw2st"
   },
   "source": [
    "Нормализуйте данные (sklearn.preprocessing.normalize) перед обучением. Что станет с качеством и почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1592395285178,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "MoQPQTeTw6j0"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "X_train_n=csr_matrix(normalize(X_train_bow_cdt))\n",
    "X_test_n=csr_matrix(normalize(X_test_bow_cdt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1592395285180,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "_VcXxnwK3HF9",
    "outputId": "fda0719e-6be0-449e-f2f3-94b56c0c205b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество логистической регресии:  0.7041111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=100).fit(X_train_n, y_train)\n",
    "print('Качество логистической регресии: ',accuracy_score(model.predict(X_test_n), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1592395285181,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "3WryuAjQ3BKn",
    "outputId": "178e1262-c86d-48e5-94a7-8ada39101a9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество SVC:  0.8072222222222222\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(max_iter=70).fit(X_train_n, y_train)\n",
    "print('Качество SVC: ',accuracy_score(model.predict(X_test_n), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DclbO7soVV2U"
   },
   "source": [
    "Что ж на SVC качестов увеличилось, а на логисточеской регрессии упало. При нормализации значения всех признаков переводятся в диапозон от 0 до 1. В нашем случаи это снижает качество логистической регресси.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ojnJe6x2XLYt"
   },
   "source": [
    "\n",
    "**mystem (0.5) балла**  \n",
    "Попробуйте обучиться, используя токенизатор mystem. Сравните качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1592395285183,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "xDBoNvCIXOLr",
    "outputId": "0959ef4d-995a-46d0-bf4d-642f7cdb4695"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-17 11:58:19--  http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
      "Resolving download.cdn.yandex.net (download.cdn.yandex.net)... 5.45.205.244, 5.45.205.241, 5.45.205.245, ...\n",
      "Connecting to download.cdn.yandex.net (download.cdn.yandex.net)|5.45.205.244|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: http://cache-mskm906.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz [following]\n",
      "--2020-06-17 11:58:19--  http://cache-mskm906.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
      "Resolving cache-mskm906.cdn.yandex.net (cache-mskm906.cdn.yandex.net)... 5.45.220.16, 2a02:6b8:0:2002::17\n",
      "Connecting to cache-mskm906.cdn.yandex.net (cache-mskm906.cdn.yandex.net)|5.45.220.16|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16457938 (16M) [application/octet-stream]\n",
      "Saving to: ‘mystem-3.0-linux3.1-64bit.tar.gz.1’\n",
      "\n",
      "\r",
      "          mystem-3.   0%[                    ]       0  --.-KB/s               \r",
      "         mystem-3.0   2%[                    ] 370.95K  1.81MB/s               \r",
      "        mystem-3.0-  54%[=========>          ]   8.50M  21.2MB/s               \r",
      "mystem-3.0-linux3.1 100%[===================>]  15.70M  30.4MB/s    in 0.5s    \n",
      "\n",
      "2020-06-17 11:58:21 (30.4 MB/s) - ‘mystem-3.0-linux3.1-64bit.tar.gz.1’ saved [16457938/16457938]\n",
      "\n",
      "mystem\n"
     ]
    }
   ],
   "source": [
    "!wget http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
    "!tar -xvf mystem-3.0-linux3.1-64bit.tar.gz\n",
    "!cp mystem /bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1592395285185,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "yGqBJRcVXsKO",
    "outputId": "fc6e2a61-f809-414f-d9e0-5e77cd200f1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/nlpub/pymystem3\n",
      "  Cloning https://github.com/nlpub/pymystem3 to /tmp/pip-req-build-fvnhj71f\n",
      "  Running command git clone -q https://github.com/nlpub/pymystem3 /tmp/pip-req-build-fvnhj71f\n",
      "Requirement already satisfied (use --upgrade to upgrade): pymystem3==0.2.0 from git+https://github.com/nlpub/pymystem3 in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pymystem3==0.2.0) (2.23.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.2.0) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.2.0) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.2.0) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.2.0) (3.0.4)\n",
      "Building wheels for collected packages: pymystem3\n",
      "  Building wheel for pymystem3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pymystem3: filename=pymystem3-0.2.0-cp36-none-any.whl size=9921 sha256=a24b2e0a1fbbfaba49e4eea03672210b67fce032b26a6ead4d853c7003bdd10c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-p0qjq67h/wheels/7d/75/c2/216a594291dee680749ce12c60d16125cfe1f363059e7163dc\n",
      "Successfully built pymystem3\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/nlpub/pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1592395285188,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "kx-OG7pdX-2p"
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "m=Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1592395285190,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "9snC0amcjUPc"
   },
   "outputs": [],
   "source": [
    "def lemmat (text: str) -> str:\n",
    "    return ''.join(m.lemmatize(text)[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IRZdRmWpasVm"
   },
   "source": [
    "Обработает строки выборки с помощью лемматизатора Mystem (ниже приведен пример)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 199,
     "status": "ok",
     "timestamp": 1592395285192,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "8kMN-teKbAUa",
    "outputId": "fa6b9f27-9529-489f-941f-3011da6ce65d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'сапог 46 размер новый'"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmat('Сапоги 46 размер новые')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1592395285194,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "sm6hhsoaUwaV"
   },
   "outputs": [],
   "source": [
    "X_train_lem=np.asarray([np.asarray([lemmat(s) for s in X_train[i]]) for i in range(X_train.shape[0])])\n",
    "X_test_lem=np.asarray([np.asarray([lemmat(s) for s in X_test[i]]) for i in range(X_test.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b8iFyW2Bb3Ay"
   },
   "source": [
    "Для того чтобы было работать с CountVectorizer, для каждого товара сложим строки его title и description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 185,
     "status": "ok",
     "timestamp": 1592395285195,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "xACmgfb1Gnoo"
   },
   "outputs": [],
   "source": [
    "X_train_cv_lem=[item[0]+' '+item[1] for item in X_train_lem]\n",
    "X_test_cv_lem=[item[0]+' '+item[1] for item in X_test_lem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 179,
     "status": "ok",
     "timestamp": 1592395285197,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "jQ9Kz-DYDQ0d"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X_train_cv_lem=cv.fit_transform(X_train_cv_lem)\n",
    "X_test_cv_lem=cv.transform(X_test_cv_lem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 171,
     "status": "ok",
     "timestamp": 1592395285198,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "fu7HDOw8vKf6",
    "outputId": "18919ca6-49cb-4b06-a92e-5f4e56ad4bb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество логистической регресии:  0.8016666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=100).fit(X_train_cv_lem, y_train)\n",
    "print('Качество логистической регресии: ', accuracy_score(model.predict(X_test_cv_lem), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 163,
     "status": "ok",
     "timestamp": 1592395285199,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "5nkUB7wyuM8P",
    "outputId": "e860e5eb-6eb6-4bb6-b844-00b7938cd996"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество SVC:  0.7891111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(max_iter=70).fit(X_train_cv_lem, y_train)\n",
    "print('Качество SVC: ',accuracy_score(model.predict(X_test_cv_lem), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oYt3iaNlo-Aw"
   },
   "source": [
    "Теперь нормализуем данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 156,
     "status": "ok",
     "timestamp": 1592395285200,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "YAbaOKdUudpC"
   },
   "outputs": [],
   "source": [
    "X_train_lem_n=csr_matrix(normalize(X_train_cv_lem))\n",
    "X_test_lem_n=csr_matrix(normalize(X_test_cv_lem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 58968,
     "status": "ok",
     "timestamp": 1592395344021,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "Gb0UL4bhwDjI",
    "outputId": "19a05462-c4d3-4977-b210-688ea8eb5fdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество логистической регресии:  0.7664444444444445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=100).fit(X_train_lem_n, y_train)\n",
    "print('Качество логистической регресии: ',accuracy_score(model.predict(X_test_lem_n), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2960,
     "status": "ok",
     "timestamp": 1592395346900,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "mEx0Aglnu4AR",
    "outputId": "8cd4476c-98e2-4fcc-9797-dca653cbf751"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество SVC:  0.8314444444444444\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(max_iter=70).fit(X_train_lem_n, y_train)\n",
    "print('Качество SVC: ',accuracy_score(model.predict(X_test_lem_n), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "98L7gU4-pTEi"
   },
   "source": [
    "В итоге, с помощью лемматизатора mystem удалось повысить качество как и логистической регрессии, так и SVC, после  нормализации качество логистической регрессии опять упало, но уже не так критично, а на SVC поднялось до рекордных пока 0.8314444444444444. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bA2ygFw-znps"
   },
   "source": [
    "**TF-IDF (1.5 балла)**  \n",
    "Не все слова полезны одинаково, давайте попробуем взвесить их, чтобы отобрать более полезные.\n",
    "\n",
    "TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    "\n",
    "IDF(t) = log_e(Total number of documents / Number of documents with term t in it).\n",
    "\n",
    "В sklearn есть TfidfVectorizer, но в этом задании его использовать нельзя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32514,
     "status": "ok",
     "timestamp": 1592395379399,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "SkzyT7cFzqwm"
   },
   "outputs": [],
   "source": [
    "# Давайте для простоты считать один tf-idf для title и description.\n",
    "# Для каждого слова из bow_vocabulary нужно посчитать\n",
    "# в тексте скольких товаров встретилось это слово\n",
    "\n",
    "text=[set(np.concatenate([sr.split() for sr in X_train[i]])) for i in range(X_train.shape[0])]\n",
    "count_arr=dict()\n",
    "for word in bow:\n",
    "  count_arr[word]=sum([1 for s in text if word in s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5EnCVmTWsYeW"
   },
   "source": [
    "count_arr - это словарь, где для 10000 самых частвовстречающихся слов (у меня  это bow) указано в скольких описаниях товаров они встретились ( описание это title+description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1592395379402,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "ITQjO8V-5SJz"
   },
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1592395379403,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "4EiuEdXkDFii"
   },
   "outputs": [],
   "source": [
    "def text_to_tfidf(text: str) -> np.array:\n",
    "    \"\"\"\n",
    "    Возвращает вектор, где для каждого слова из most_common\n",
    "    указан tf-idf\n",
    "    \"\"\"\n",
    "    words=text.split()\n",
    "    return np.asarray([words.count(word)/len(words)*log(21000/count_arr[word]) for word in bow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1592395379404,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "eCFUknE_6JRE"
   },
   "outputs": [],
   "source": [
    "def items_to_tfidf(items: np.array) -> np.array:\n",
    "    \"\"\" Для каждого товара возвращает вектор его tf-idf\"\"\"\n",
    "    \n",
    "    return np.asarray([text_to_tfidf(item[0]+' '+item[1]) for item in items])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KbWJ-Em-yXUv"
   },
   "source": [
    "tf-idf для товара считается от сложения его строк title и description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 493504,
     "status": "ok",
     "timestamp": 1592395872895,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "kthVNIy_9s6Q"
   },
   "outputs": [],
   "source": [
    "X_train_tfidf = csr_matrix(items_to_tfidf(X_train))\n",
    "X_test_tfidf = csr_matrix(items_to_tfidf(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1592395872902,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "-xgRsOwG1qy7"
   },
   "outputs": [],
   "source": [
    "# Нормализуйте данные\n",
    "from sklearn.preprocessing import normalize\n",
    "X_train_tf_n=csr_matrix(normalize(X_train_tfidf))\n",
    "X_test_tf_n=csr_matrix(normalize(X_test_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aY0L22BRrSad"
   },
   "source": [
    "**Модели на TF-IDF признаках (1 балл)**  \n",
    "Обучите логистическую регрессию и SVC, оцените качество (accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29254,
     "status": "ok",
     "timestamp": 1592395902127,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "Pm4kuSI--EY_",
    "outputId": "12a82203-1d15-426f-a851-b8fa082dde4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество логистической регресии:  0.7653333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=100).fit(X_train_tf_n, y_train)\n",
    "print('Качество логистической регресии: ',accuracy_score(model.predict(X_test_tf_n), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2496,
     "status": "ok",
     "timestamp": 1592395904590,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "qqqzjrc2-R81",
    "outputId": "0d4c5b1e-da82-462b-ab56-802b492c42e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество SVC:  0.8067777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = LinearSVC(max_iter=70).fit(X_train_tf_n, y_train)\n",
    "print('Качество SVC: ',accuracy_score(model.predict(X_test_tf_n), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mCoZqhGC2GYn"
   },
   "source": [
    "Что ж если сравнивать с методом BOW после нормализации, то качество на логистической регрессии удалось повысить на 0,06 , а на SVC оно почти не изменилось. В общем, качество достаточно высокое, но проирывает полученному с помощью лемматизатора mystem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ro2pQV-wI3Oz"
   },
   "source": [
    "**Hashing Vectorizer (0.5 балла)**  \n",
    "Попробуйте использовать sklearn.feature_extraction.text.HashingVectorizer для векторизации текстов. Обязательно оцените качество работы алгоритмов классификации с использованием новой векторизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1592395904594,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "rDPCDEaGI9VY"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F0_KlRwqIsWO"
   },
   "source": [
    "Опять сложим title и description каждого товара для того чтобы, воспользоваться HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 529,
     "status": "ok",
     "timestamp": 1592395905086,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "r5DAAkgbN1Tj"
   },
   "outputs": [],
   "source": [
    "X_train_vec=np.asarray([X_train[i][0]+' '+X_train[i][1] for i in range(X_train.shape[0])])\n",
    "X_test_vec=np.asarray([X_test[i][0]+' '+X_test[i][1] for i in range(X_test.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1672,
     "status": "ok",
     "timestamp": 1592395906727,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "TM-aakoXLFqd"
   },
   "outputs": [],
   "source": [
    "vectorizer = HashingVectorizer(n_features=100000)\n",
    "X_train_hash=vectorizer.fit_transform(X_train_vec)\n",
    "X_test_hash=vectorizer.transform(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 101460,
     "status": "ok",
     "timestamp": 1592396008164,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "29OASOD5PGSV",
    "outputId": "f1918f55-e665-4c62-a700-6b323456e621"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество логистической регресии:  0.7371111111111112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "bow_model = LogisticRegression(max_iter=100).fit(X_train_hash, y_train)\n",
    "print('Качество логистической регресии: ',accuracy_score(bow_model.predict(X_test_hash), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2628,
     "status": "ok",
     "timestamp": 1592396010771,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "sjfE6FWHQmmd",
    "outputId": "0983ae08-e776-4336-b485-8a7148f056f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество SVC:  0.8247777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = LinearSVC(max_iter=70).fit(X_train_hash, y_train)\n",
    "print('Качество SVC: ',accuracy_score(model.predict(X_test_hash), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cR4Kit2LTFKX"
   },
   "source": [
    "**Word Vectors (1 балл)**  \n",
    "Давайте попробуем другой подход -- кажому слову сопоставим какой-то эмбеддинг (вектор).\n",
    "\n",
    "Вектора будут небольшой размерности. Таким образом мы снизим количество параметров в модели.\n",
    "\n",
    "Вектора мы возьмём уже готовые (обученные на текстах их интернета), так что наша модель будет знать некоторую дополнительную информацию о внешнем мире."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 106581,
     "status": "ok",
     "timestamp": 1592396117311,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "4pFZ9h8WTILN",
    "outputId": "af4c0651-6667-4962-c411-514e923f4720"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-17 12:13:35--  https://www.dropbox.com/s/0x7oxso6x93efzj/ru.tar.gz\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/0x7oxso6x93efzj/ru.tar.gz [following]\n",
      "--2020-06-17 12:13:35--  https://www.dropbox.com/s/raw/0x7oxso6x93efzj/ru.tar.gz\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uce509eadd95d70f30bc44c98d08.dl.dropboxusercontent.com/cd/0/inline/A50F8T3uwdh-7h2CO2iirjQwjIqiSw9P3EuGjvVoOKpwyjJ1x2_6XbR6Nj26c70gsVrP8KLkQbpVLwuu2yZcyGZlHMzoQw2izaWXTV_lFzB1AQ/file# [following]\n",
      "--2020-06-17 12:13:36--  https://uce509eadd95d70f30bc44c98d08.dl.dropboxusercontent.com/cd/0/inline/A50F8T3uwdh-7h2CO2iirjQwjIqiSw9P3EuGjvVoOKpwyjJ1x2_6XbR6Nj26c70gsVrP8KLkQbpVLwuu2yZcyGZlHMzoQw2izaWXTV_lFzB1AQ/file\n",
      "Resolving uce509eadd95d70f30bc44c98d08.dl.dropboxusercontent.com (uce509eadd95d70f30bc44c98d08.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6021:15::a27d:410f\n",
      "Connecting to uce509eadd95d70f30bc44c98d08.dl.dropboxusercontent.com (uce509eadd95d70f30bc44c98d08.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /cd/0/inline2/A51pck2hlYdPW2LhWhxHqWpHsoRFIg88qhxh_Mk8GcEgbXZTV_hjnGMPHMD6xQr-drVdjwv2BZ3OkSrJRGy75Ozaiea2r_y6yofYeWuOrJTVJJZXpb4_hKlFTXV3nsC6UFohzOIUlVwBWlm1Gv70ije53HKaf8okGc6pnfr-uukiw2MjH1e446f_Fgx_BCtegSfQ26UROP9HZgMdMmYbZC9FmQF6UcGs1U2C7uuIO-s3S--i93KUXLVseog88iyPM8R4J3Za2ExaP1xXSnk4F_3_4_qilFiNqzGKsTcUfhBGWJYh20dEz_C1wB4IPwmOR5XKcFY3KXvGkXFbctojAxfS/file [following]\n",
      "--2020-06-17 12:13:36--  https://uce509eadd95d70f30bc44c98d08.dl.dropboxusercontent.com/cd/0/inline2/A51pck2hlYdPW2LhWhxHqWpHsoRFIg88qhxh_Mk8GcEgbXZTV_hjnGMPHMD6xQr-drVdjwv2BZ3OkSrJRGy75Ozaiea2r_y6yofYeWuOrJTVJJZXpb4_hKlFTXV3nsC6UFohzOIUlVwBWlm1Gv70ije53HKaf8okGc6pnfr-uukiw2MjH1e446f_Fgx_BCtegSfQ26UROP9HZgMdMmYbZC9FmQF6UcGs1U2C7uuIO-s3S--i93KUXLVseog88iyPM8R4J3Za2ExaP1xXSnk4F_3_4_qilFiNqzGKsTcUfhBGWJYh20dEz_C1wB4IPwmOR5XKcFY3KXvGkXFbctojAxfS/file\n",
      "Reusing existing connection to uce509eadd95d70f30bc44c98d08.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2399456034 (2.2G) [application/octet-stream]\n",
      "Saving to: ‘ru.tar.gz.1’\n",
      "\n",
      "ru.tar.gz.1         100%[===================>]   2.23G  25.0MB/s    in 94s     \n",
      "\n",
      "2020-06-17 12:15:11 (24.4 MB/s) - ‘ru.tar.gz.1’ saved [2399456034/2399456034]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/0x7oxso6x93efzj/ru.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 59601,
     "status": "ok",
     "timestamp": 1592396176889,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "8mPNsOO2TYY_",
    "outputId": "f80ea259-843d-44c6-9de8-cfc01163595c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ru.bin\n",
      "ru.vec\n"
     ]
    }
   ],
   "source": [
    "!tar -xzvf ru.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11817,
     "status": "ok",
     "timestamp": 1592396188683,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "FtfqPg_mTgjh"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.wrappers import FastText\n",
    "\n",
    "model = FastText.load_fasttext_format('ru.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 88,
     "status": "ok",
     "timestamp": 1592396188687,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "TUszvzLfTm1g"
   },
   "outputs": [],
   "source": [
    "# Эмбеддинг предложения -- сумма эмбеддингов токенов\n",
    "\n",
    "def sentence_embedding(sentence: str) -> np.array:\n",
    "    \"\"\"\n",
    "    Складывает вектора токенов строки sentence\n",
    "    \"\"\"\n",
    "\n",
    "    embedding_dim = model['кек'].shape[0]\n",
    "    features = np.zeros([embedding_dim], dtype='float32')\n",
    "    \n",
    "    for word in sentence.split():\n",
    "        if word in model:\n",
    "            features += model[word]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1592396188690,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "Zq3bG1kKXq0L"
   },
   "outputs": [],
   "source": [
    "assert np.allclose(sentence_embedding('сдаётся уютный , тёплый гараж для стартапов в ml')[::50],\n",
    "                   np.array([ 0.08189847,  0.07249198, -0.15601222,  0.03782297,  0.09215296, -0.23092946]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1592396188693,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "tr__XNpIVJOA"
   },
   "outputs": [],
   "source": [
    "def items_to_vec(items: np.array) -> np.array:\n",
    "    return np.asarray([sentence_embedding(item[0])+sentence_embedding(item[1]) for item in items])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rVsKEJfTNt6E"
   },
   "source": [
    "Закодируем каждый товар, как сумму векторов полученных применением sentence_embedding к title и description товара"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34316,
     "status": "ok",
     "timestamp": 1592396223708,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "MRjVkxf3WGeK"
   },
   "outputs": [],
   "source": [
    "X_train_wv=items_to_vec(X_train)\n",
    "X_test_wv=items_to_vec(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12496,
     "status": "ok",
     "timestamp": 1592396236187,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "1UtYZ_mPWtQJ",
    "outputId": "999a0094-feef-4fc0-c0e2-108c68b0c355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество логистической регресии:  0.5523333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=100).fit(X_train_wv, y_train)\n",
    "print('Качество логистической регресии: ',accuracy_score(model.predict(X_test_wv), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 67350,
     "status": "ok",
     "timestamp": 1592396303514,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "ZHdCtQIeWfwR",
    "outputId": "bc769c3c-5831-4c45-d016-4123b4b3542e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество SVC:  0.46266666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "model = LinearSVC(max_iter=70).fit(X_train_wv, y_train)\n",
    "print('Качество SVC: ',accuracy_score(model.predict(X_test_wv), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PaxlkOIsQuwQ"
   },
   "source": [
    "Что ж качество сильно упало по сравнению с предыдущими методами кодирования товаров, я думаю, что это связано с тем, что тексты из интернета не отражают специфику нашей классификации и небольшой размерностью векторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1592396303516,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "lqIRzes0YJMB"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "X_train_wv_n=normalize(X_train_wv)\n",
    "X_test_wv_n=normalize(X_test_wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13203,
     "status": "ok",
     "timestamp": 1592396316710,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "_n9W2SnjYgf1",
    "outputId": "21eb6560-be00-41fb-845b-ce29f8d15d73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество логистической регресии:  0.49466666666666664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=100).fit(X_train_wv_n, y_train)\n",
    "print('Качество логистической регресии: ',accuracy_score(model.predict(X_test_wv_n), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 26064,
     "status": "ok",
     "timestamp": 1592396342736,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "3qxBzbipYnPV",
    "outputId": "8f2803ae-1625-4047-dccb-5fc5a1466be8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество SVC:  0.562\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = LinearSVC(max_iter=70).fit(X_train_wv_n, y_train)\n",
    "print('Качество SVC: ',accuracy_score(model.predict(X_test_wv_n), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GMaaLYevGqT5"
   },
   "source": [
    "После нормализации качесто на SVC поднялось, а на логистической  регрессии уменьшилось как обычно, но в целом этот метод серьезно проигрывает всем предыдущим."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xsaYt9rNY8S2"
   },
   "source": [
    "**Что дальше?**  \n",
    "Решение каждого пункта 1 балл:\n",
    "\n",
    "\n",
    "1.   N-Gram модели текстовой классификации\n",
    "2.   Обучиться на полных данных (контест на kaggle)\n",
    "3.   Поработать с другими эмбеддингами (word2vec, GloVe).\n",
    "4.   Использовать Vowpal Wabbit вместо sklearn.\n",
    "5.   Другие способы токенизации (pymorphy2, spaCy)\n",
    "\n",
    "\n",
    "Снабжайте код пояснениями и графиками. Обязательно необходимо написать вывод по каждому пункту, который вы реализуете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HoK2IVNfw8zd"
   },
   "source": [
    "**N-Gram модели текстовой классификации**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1592396343471,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "3laQrFqEBw5Q"
   },
   "outputs": [],
   "source": [
    "X_train_vec=[item[0]+' '+item[1] for item in X_train]\n",
    "X_test_vec=[item[0]+' '+item[1] for item in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1592396343474,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "xINCvQhYCzje"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 196592,
     "status": "ok",
     "timestamp": 1592396540045,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "vvl7sfL3DR9e",
    "outputId": "39872c60-c66c-43f2-90b9-8ebf0c9257a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-Gram range: (1, 1) accuracy:  0.8352222222222222\n",
      "N-Gram range: (1, 2) accuracy:  0.8295555555555556\n",
      "N-Gram range: (1, 3) accuracy:  0.8178888888888889\n",
      "N-Gram range: (1, 5) accuracy:  0.8033333333333333\n",
      "N-Gram range: (2, 2) accuracy:  0.7045555555555556\n",
      "N-Gram range: (2, 5) accuracy:  0.66\n",
      "N-Gram range: (3, 3) accuracy:  0.5366666666666666\n"
     ]
    }
   ],
   "source": [
    "ngram_range=[(1,1),(1,2),(1,3),(1,5),(2,2),(2,5),(3,3)]\n",
    "svc = LinearSVC(max_iter=70)\n",
    "tfidf = TfidfVectorizer()\n",
    "for n in ngram_range:\n",
    "  tfidf.ngram_range=n\n",
    "  X_train_t=tfidf.fit_transform(X_train_vec)\n",
    "  X_test_t=tfidf.transform(X_test_vec)\n",
    "  svc.fit(X_train_t, y_train)\n",
    "  print('N-Gram range:', n,'accuracy: ',accuracy_score(svc.predict(X_test_t), y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kvZZW9q8DUbJ"
   },
   "source": [
    "С увелечением n_gram range качество уменьшаеться. Самое высокое качество было достигнуто с n_gram=(1,1)  0.8352222222222222"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KkmoQg_wMit2"
   },
   "source": [
    "**Поработать с другими эмбеддингами (word2vec, GloVe).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Th5i0qToMnKe"
   },
   "source": [
    "Я пыталась по аналогии с заданием wordvec поработать с word2vec. Вектора я тоже брала уже готовые. Насколько у меня получилось судить вам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14534,
     "status": "ok",
     "timestamp": 1592396554568,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "KkxA-gzq4Z8f",
    "outputId": "29162484-4833-4c27-b13d-550209bcaf2a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "model2 = KeyedVectors.load_word2vec_format('ru.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1592396554573,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "SAT-AYsAJ54J"
   },
   "outputs": [],
   "source": [
    "# Эмбеддинг предложения -- сумма эмбеддингов токенов\n",
    "\n",
    "def sentence_embedding2(sentence: str) -> np.array:\n",
    "    \"\"\"\n",
    "    Складывает вектора токенов строки sentence\n",
    "    \"\"\"\n",
    "\n",
    "    embedding_dim = model2['мама'].shape[0]\n",
    "    features = np.zeros([embedding_dim], dtype='float32')\n",
    "    \n",
    "    for word in sentence.split():\n",
    "        if word in model2:\n",
    "            features += model2[word]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1592396554577,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "SU9wv42v4omf"
   },
   "outputs": [],
   "source": [
    "def items_to_vec2(items: np.array) -> np.array:\n",
    "    return np.asarray([sentence_embedding2(item[0])+sentence_embedding2(item[1]) for item in items])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eBP4fZPXSyVi"
   },
   "source": [
    "Закодируем каждый товар, как сумму векторов полученных применением sentence_embedding2 к title и description товара"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6329,
     "status": "ok",
     "timestamp": 1592396560875,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "_xWbkl0U5RKw"
   },
   "outputs": [],
   "source": [
    "X_train_wv2=items_to_vec2(X_train)\n",
    "X_test_wv2=items_to_vec2(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11543,
     "status": "ok",
     "timestamp": 1592396572410,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "YZqof_CuL_MC",
    "outputId": "813de2a0-dfbb-4be3-8655-2ff1d85c265e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество логистической регресии:  0.6615555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=100).fit(X_train_wv2, y_train)\n",
    "print('Качество логистической регресии: ',accuracy_score(model.predict(X_test_wv2), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 54995,
     "status": "ok",
     "timestamp": 1592396627386,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "O0xtZn3GKgY-",
    "outputId": "05f1ec00-f238-4141-e3a9-a53d4d7239f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество SVC:  0.5385555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "model = LinearSVC(max_iter=70).fit(X_train_wv2, y_train)\n",
    "print('Качество SVC: ',accuracy_score(model.predict(X_test_wv2), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T0WT5i7SUJ7K"
   },
   "source": [
    "Нормализуем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1592396627389,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "5Sdww-9VObbR"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "X_train_wv2_n=normalize(X_train_wv2)\n",
    "X_test_wv2_n=normalize(X_test_wv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12673,
     "status": "ok",
     "timestamp": 1592396640039,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "qatUd547OjbI",
    "outputId": "56a87e54-56ca-4773-85ac-cf3cadb7409e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество логистической регресии:  0.6141111111111112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=100).fit(X_train_wv2_n, y_train)\n",
    "print('Качество логистической регресии: ',accuracy_score(model.predict(X_test_wv2_n), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20762,
     "status": "ok",
     "timestamp": 1592396660792,
     "user": {
      "displayName": "Sofya Gust",
      "photoUrl": "",
      "userId": "00505749329728850226"
     },
     "user_tz": -180
    },
    "id": "1R2TLC27O0d7",
    "outputId": "44249861-2f43-4bad-8a5d-0bea6d8db028"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество SVC:  0.6686666666666666\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(max_iter=70).fit(X_train_wv2_n, y_train)\n",
    "print('Качество SVC: ',accuracy_score(model.predict(X_test_wv2_n), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F3jU9x_FUSkd"
   },
   "source": [
    "Что ж этот способ получился получше, чем fasttext в задании wordvec, но качество все еще не очень высокое (0.6686666666666666 максимальное) и проигрывает всем остальным способам векторизации текстов."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Homework3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
